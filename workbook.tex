% !TeX spellcheck = en_US
\documentclass[12pt,a4paper,oneside]{book}
% oneside or openright

%% ***************************************************************
%%    PACKAGES
\usepackage{lmodern}         % font package.
\usepackage[T1]{fontenc}     % define T1 charset for out files.
\usepackage[english]{babel}  % italian latex typo conventions.
\usepackage[utf8]{inputenc}  % italian symbols.
\usepackage{csquotes}        % needed by babel.
\usepackage{amsmath}         % math features.
\usepackage{amsthm}          % math theorems.
\usepackage{amssymb}         % math symbols.
\usepackage{amsbsy}          % math bold.
\usepackage{mathtools}       % math tools.
\usepackage{listings}        % embed programming language in latex.
\usepackage{stmaryrd}        % symbols for theoretical computer science.
\usepackage{hhline}          % better horizontal lines in tabulars and arrays.
%%\usepackage{vmargin}         % various page dimensions.
\usepackage{hyperref}        % hypertext support.
\usepackage{makeidx}         % for creating indexes.
\usepackage{nicefrac}        % inline fractions.
\usepackage{marginnote}      % notes in the margin, even where \marginpar fails.
\usepackage{xr}              % references to other latex documents.
\usepackage{subfiles}        % multifile support.
\usepackage{geometry}        % interface for document dimension.
\usepackage{graphicx}        % enhanced support for graphics.
\usepackage{fancyhdr}        % extensive control of page headers and footers.
\usepackage{lipsum}          % generate dummy text.
\usepackage[
backend=biber,
style=numeric,
citestyle=numeric  % numeric, alphabetic
]{biblatex}                  % bib management. %bibtex
\usepackage{minitoc}         % table of contents per chapter.
%\usepackage{titlesec}        % change titles size.
\usepackage{algorithm}       % algorithm block.
\usepackage{algcompatible}
\usepackage{algpseudocode}   % style for (autoimported) package algorithmicx.
\usepackage{float}           % float management.
\usepackage[toc,page]{appendix}  % appendix.
\usepackage{tcolorbox}
%\usepackage{minted}
\usepackage{tikz}            % flow chart.
%\usepackage{tocvsec2}        % numbering chapter fix.
\usepackage{enumitem}        % enums.
%\usepackage{subcaption}      % needed by nested figures.
%\usepackage{showframe}      % DEBUG: shows page frames.
\usepackage{xcolor}

%% ***************************************************************
%%    RESOURCES
\input{prooftree.tex}
\input{macros.tex}

%% ***************************************************************
%%    CONFIGURATIONS
\usetikzlibrary{calc,trees,positioning,arrows,chains,shapes.geometric,%
    decorations.pathreplacing,decorations.pathmorphing,shapes,%
    matrix,shapes.symbols}
\tikzset{
    % flow chart
    >=stealth',
    punktchain/.style={
        rectangle,
        rounded corners,
        % fill=black!10,
        draw=black, very thick,
        text width=10em,
        minimum height=3em,
        text centered,
        on chain},
    line/.style={draw, thick, <-},
    element/.style={
        tape,
        top color=white,
        bottom color=blue!50!black!60!,
        minimum width=8em,
        draw=blue!40!black!90, very thick,
        text width=10em,
        minimum height=3.5em,
        text centered,
        on chain},
    every join/.style={->, thick,shorten >=1pt},
    decoration={brace},
    tuborg/.style={decorate},
    tubnode/.style={midway, right=2pt},
}

%% ***************************************************************
%%    OPENING
\title{Workbook \\ Master Degree in Computer Science}
\author{Luca Parolari\footnote{\href{mailto:luca.parolari23@gmail.com}{luca.parolari23@gmail.com}}}


%% ###############################################################
%%                            DOCUMENT
%% ###############################################################
\begin{document}

\maketitle
\tableofcontents

\part{AA 2019-2020}

% *********************
\chapter{Software Analysis and Verification}

\section{Semantics}

\subsection{Exercise 1.7}

\begin{exercise}{(1.7)}
    \label{ex_1_7}
    Prove that the equations of Equation \ref{eq_ex_1_7} define a
    total function $\calA$ in $\AExp \to (\ST \to \mathrm{Z})$: First
    argue that it is sufficient to prove that for each $a \in \AExp$
    and each $s \in \ST$ there is exactly one value $v \in Z$ such
    that $\denotA{a}{s} = v$. Next use structural induction on the
    arithmetic expressions to prove that this is indeed the case.

    \begin{equation}
    \label{eq_ex_1_7}
    \begin{split}
    \denotA{n}{s} &= \denotN{n} \\
    \denotA{x}{s} &= s x \\
    \denotA{a_1+a_2}{s} &= \denotA{a_1}{s} + \denotA{a_2}{s} \\
    \end{split}
    \end{equation}

    \begin{proof}
        We have to prove that
        \[
        \forall a \in \AExp \itc \forall s \in \ST: \exists v \in \mathrm{Z} \st \denotA{a}{s} = v
        \]
        and we can do it by structural induction on $a$.

        \begin{itemize}
            \item Base case $a \equiv n$. $\denotA{n}{s} = \denotN{n}$ holds assuming $\denotN{n}$ is a total function.
            \item Base case $a \equiv x$. $\denotA{x}{s} = s x$ holds by definition of $s$ ($\fund{s}{\Var}{\Natural}$).
            \item Inductive case $a \equiv a_1 + a_2$. We can apply the definition for this case and we obtain
            \[
            \forall a_1, a_2 \in \AExp \itc \forall s \in \ST: \exists v \in \mathrm{Z} \st \denotA{a_1 + a_2}{s} = v
            \]
            and this, by structural induction and because $+$ is a total function, holds.
        \end{itemize}
    \end{proof}

\end{exercise}

\subsection{Exercise 1.8}

\begin{exercise}{(1.8)}
    Assume that $s\ x = 3$ and determine $\denotB{\notop(x = 1)}{s}$.

    \begin{proof}
        We have to apply rules from our semantics in order to get the result.

         \todo{Finish this exercise}
    \end{proof}
\end{exercise}

\subsection{Exercise 1.9}

\begin{exercise}{(1.9)}
    Prove that the denotation semantic function for booleans $\calB$, $\fund{\calB}{\BExp}{(\ST \to \mathrm{T})}$ is total.

    \begin{proof}
        Identical to Exercise \ref{ex_1_7}
    \end{proof}
\end{exercise}

\subsection{Exercise 1.10}

\begin{exercise}{(1.10)}
     \todo{Add this exercise}
\end{exercise}

\subsection{Exercise 1.12}

\begin{exercise}
    Let $s$ and $s'$ be two states satisfying that $s x = s' x$ for
    all $x$ in $FV(b)$. Prove that $\denotB{b}{s} = \denotB{b}{s'}$. $\FV$
    is defined in Definition \ref{ex_1_12_fv}.

    \begin{proof}
        We assume that this sentences holds for $\calA$. (This is
        proved in Lemma \ref{ex_1_12_lemma}). We have to prove that
        \[
        \forall b \in \BExp \itc \forall s, s' \in \ST \itc \forall x \in \FV(a) \itc sx = s'x \Rightarrow \denotB{b}{s} = \denotB{b}{s'}
        \]

    \end{proof}
\end{exercise}

\begin{definition}
    \label{ex_1_12_fv}
    Define FV \todo{define FV}
\end{definition}

\begin{lemma}
    \label{ex_1_12_lemma}
    \[
    \forall a \in \AExp \itc \forall s, s' \in \ST \itc \forall x \in \FV(a) \itc sx = s'x \Rightarrow \denotA{a}{s} = \denotA{a}{s'}
    \]

    \begin{proof}
        We have to prove that
        \[
        \forall a \in \AExp \itc \forall s, s' \in \ST \st sx = s'x \Rightarrow \denotA{b}{s} = \denotA{b}{s'}
        \]
        and we can do it by structural induction on $b$.

        \begin{itemize}
            \item Base case $a \equiv n$. It's trivial to note that $\denotA{n}{s} = \denotN{n} = n = n = \denotN{n} = \denotB{n}{s'}$.
            \item Base case $a \equiv x$. In this case we have
        \end{itemize}
    \end{proof}
\end{lemma}

\subsection{Exercise 2.17}
\begin{exercise}
    Extend While with the construct repeat $S$ until $b$ and specify a
    structural operational semantics for it. (The semantics for the
    repeat-construct is not allowed to rely on the existence of a
    while-construct.)

    \begin{proof}
        \prooftree
        \justifies
          \config{\repeatuntil{S}{b}}{s} \to \config{S; \condif{b}{\repeatuntil{S}{b}}{skip}}{s}
        \endprooftree
    \end{proof}
\end{exercise}

\subsection{Exercise 1.13}

\begin{exercise}
    Prove that $\denotA{ a[y \to a_0] }{s} = \denotA{a}{s[y \to \denotA{a_0}{s}]}$, $\forall s \in \ST$.

    \begin{proof}
        \todo {Copiare la dimostrazione dal quaderno!}
    \end{proof}
\end{exercise}

\subsection{Decomposition Lemma}

\begin{theorem}{(Decomposition Lemma)}
    If $\config{S_1; S_2}{s} \to^k s''$ then $\exists s', k_1, k_2 \st \config{S_1}{s} \to^{k_1} s' \land \config{S_2}{s'} \to^{k_2} s'' \land k = k_1 + k_2$

    \begin{proof}
        By induction on the length of the derivation sequence $k$.

        \begin{itemize}
            \item Case $k=0$. The configuration $\config{S_1;S_2}{s}
              \not\to^0$ cannot be derived, so this is trivially true.

            \item Case $k+1$. We have $\config{S_1;S_2}{s} \to^{k+1}
              s''$. We can explicit a derivation step
              $\config{S_1;S_2}{s} \to \gamma \to^{k} s''$.

            $\gamma$ is a new configuration with the form
            \begin{itemize}
                \item $\config{S_1';S_2}{s'}$ if applied $\textrm{comp}^{1}_{\textrm{sos}}$. So, we have
                \[
                    \config{S_1;S_2}{s} \to \config{S_1';S_2}{s'} \to^{k} s''
                \]
                and by the inductive hypothesis we know that $\exists
                s''', j_1, j_2 \st \config{S_1'}{s'} \to^{j_1} s'''
                \land \config{S_2}{s'''} \to^{j_2} s''$. Combining
                everything together we can note that $k_1 = j_1 + 1$
                and $k_2 = j_2$. From this $k + 1 = k_1 + 1 + k_2 =
                j_1 + 1 + j_2$.

                \item $\config{S_2}{s'}$ if applied $\textrm{comp}^{2}_{\textrm{sos}}$. From this $k_1 = 1$ and $k_2 = k$, so $k + 1 = k_1 + k_2 = k + 1$.
            \end{itemize}
        \end{itemize}
    \end{proof}
\end{theorem}

\subsection{Compostition Lemma}

\begin{theorem}
     If $\config{S_1}{s} \to^k s'$ then $\config{S_1;S_2}{s} \to^k \config{S_2}{s'}$.

     \begin{proof}
        By induction on the length of the derivation sequence $k$.

        \begin{itemize}
            \item Base case: $k = 0$. $\config{S}{s} \to^0 s'$, holds trivially.
            \item Inductive case: $l = k+1$.
        \end{itemize}

        \todo{Finire}
     \end{proof}
\end{theorem}

\subsection{Small-step semantics determinism}

% *********************
\chapter{Machine Learning}

\section{Decision Trees}

\subsection{Exercise: build a decision tree}

\begin{exercise}
    Using algorithm \emph{ID3} build the decision trees for logical AND, OR and XOR.

    \begin{proof} (AND)
        Define the examples set $S$ as
        \begin{center}
            \begin{tabular}{ c c c c }
                \textbf{Examples} & \textbf{$a_1$} & \textbf{$a_2$} & \textbf{Output} \\
                $E_1$ & 0 & 0 & $\ffv$ \\
                $E_2$ & 0 & 1 & $\ffv$ \\
                $E_3$ & 1 & 0 & $\ffv$ \\
                $E_4$ & 1 & 1 & $\ttv$
            \end{tabular}
        \end{center}
        where $a_1, a_2$ are attributes in $A$, $\ttv, \ffv$ are the
        two possible classes and $0, 1$ are the two possible values.

        Now we can apply the algorithm \emph{ID3}.
        \begin{itemize}
            \item \textbf{Step 1} We create the root node $T$. The two
              tests fail: examples in $S$ are not in the same class
              and $A$ is not empty. So we have to chose $a \in A$ as
              the best attribute in $A$.

            In order to chose the best attribute in $A$ we must
            calculate the \emph{entropy} (i.e., a measure of the
            disorder) and the \emph{information gain} (i.e., the
            expected reduction of entropy for a given set).

            Entropy is
            \[
            E(S) = - \sum_{c=1}^{m} p_c \log(p_c)
            \]
            where $p_c = \frac{|S_c|}{|S|}$, but for a binary
            classification it becomes
            \[
            E(S) = - p_- \log(p_-) - p_+ \log(p_+)
            \]

            And the gain
            \[
            G(S,a) = E(S) - \sum_{v\in V(a)} \frac{|S_{a=v}|}{|S|} E(S_{a=v})
            \]

            So, instancing the two formulas on our data we obtain
            \[
            p_- = \frac{|S_-|}{|S|} = \frac{3}{4} \qquad p_+ = \frac{|S_+|}{|S|} = \frac{1}{4}
            \]
            and
            \[
            E(S) = - \frac{3}{4} \log\big(\frac{3}{4}\big) - \frac{1}{4} \log\big(\frac{1}{4}\big) = 0.244
            \]
            From this, we can calculate the gain as
            \begin{equation*}
            \begin{split}
            G(S, a_1) &= 0.244 - \Big( \big(\frac{|S_{a_1=0}|}{|S|} E(S_{a_1=0})\big) + \big(\frac{|S_{a_1=1}|}{|S|} E(S_{a_1=1})\big) \Big) \\
            &= 0.244 - \Big( \big(\frac{2}{4} E(S_{a_1=0})\big) + \big(\frac{2}{4} E(S_{a_1=1})\big) \Big) \\
            &= 0.244 - (0 + 0.25) \\
            &= -0.006  \law{\color{red}{WTF??}}
            \end{split}
            \end{equation*}
            \fixme{Non può essere negativo!}

            From the above we can chose the attribute $a_1$, set it as
            $T$ and make two recursive call:
            \begin{itemize}
                \item $ID3(S_{a_1=0}, A \setdiff \{a_1\})$
                \item $ID3(S_{a_1=1}, A \setdiff \{a_1\})$
            \end{itemize}

            \item \textbf{Step 2} First recursive call from Step 1. We
              have $S = \{ \langle 0,0,\ffv \rangle, \langle 0,1,\ffv
              \rangle \}$, $A = \{a_2\}$. We create a new root node
              $T$ and we can assign $\ffv$ to it because the elements
              in $S$ have the same class.

            \item \textbf{Step 3} Second recursive call from Step
              1. We have $S = \{ \langle 1,0,\ffv \rangle, \langle
              1,1,\ttv \rangle \}$, $A=\{a_2\}$. We create a new root
              node $T$ and assign $a_2$ to it because $a_2$ is the
              last attribute in $A$ (i.e., the optimal one), then we
              can make the recursive call:
            \begin{itemize}
                \item $ID3(S_{a_2=0}, A \setdiff \{a_2\})$
                \item $ID3(S_{a_2=1}, A \setdiff \{a_2\})$
            \end{itemize}

            \item \textbf{Step 4} First recursive call from Step 3. We
              have $S=\{\langle 1,0,\ffv \rangle \}$ and for this we
              can assign $\ffv$ to $T$ since it is the last element in
              $S$, making a leaf.

            \item \textbf{Step 5} Second recursive call from Step
              3. We have $S=\{ \langle 1,1,\ttv \rangle \}$ and for
              this we can assign $\ttv$ to $T$ since it is the last
              element in $S$, making a leaf.
        \end{itemize}

        \begin {tikzpicture}[-latex ,auto ,node distance =2 cm and 2cm, on grid, semithick, state/.style ={ circle ,top color =white , bottom color = white, draw, black , text=black, minimum width =1 cm}]
            \node[state] (A) {$a_1$};
            \node[state] (B) [below left =of A] {$\ffv$};
            \node[state] (C) [below right =of A] {$a_2$};
            \node[state] (D) [below left =of C] {$\ffv$};
            \node[state] (E) [below right =of C] {$\ttv$};
            \path (A) edge node {$0$} (B);
            \path (A) edge node {$0$} (C);
            \path (C) edge node {$0$} (D);
            \path (C) edge node {$1$} (E);
        \end{tikzpicture}
    \end{proof}
\end{exercise}

\begin{exercise}
Using algorithm \emph{ID3} build the decision trees for logical AND,
OR and XOR. This time only three examples are given.

\begin{proof} (AND)
    Define the examples set $S$ as
    \begin{center}
        \begin{tabular}{ c c c c }
            \textbf{Examples} & \textbf{$a_1$} & \textbf{$a_2$} & \textbf{Output} \\
            $E_1$ & 0 & 0 & $\ffv$ \\
            $E_2$ & 0 & 1 & $\ffv$ \\
            $E_4$ & 1 & 1 & $\ttv$ \\
        \end{tabular}
    \end{center}
    where $a_1, a_2$ are attributes in $A$, $\ttv, \ffv$ are the two
    possible classes and $0, 1$ are the two possible values.

    Now we can apply the algorithm \emph{ID3}.
    \begin{itemize}
        \item \textbf{Step 1} We create the root node $T$. The two
          tests fail: examples in $S$ are not in the same class and
          $A$ is not empty. So we have to chose $a \in A$ as the best
          attribute in $A$.

        For simplicity this part is skipped and $a_1$ is chosen as the
        optimal attribute.

        From the above we can chose the attribute $a_1$, set it as $T$
        and make two recursive call:
        \begin{itemize}
            \item $ID3(S_{a_1=0}, A \setdiff \{a_1\})$
            \item $ID3(S_{a_1=1}, A \setdiff \{a_1\})$
        \end{itemize}

        \item \textbf{Step 2} First recursive call from Step 1. We
          have $S = \{ \langle 0,0,\ffv \rangle, \langle 0,1,\ffv
          \rangle \}$, $A = \{a_2\}$. We create a new root node $T$
          and we can assign $\ffv$ to it because the elements is $S$
          are have the same class.

        \item \textbf{Step 3} Second recursive call from Step 1. We
          have $S = \{ \langle 1,1,\ttv \rangle \}$, $A=\{a_2\}$. We
          create a new root node $T$ and assign $\ttv$ to it because
          elements in $S$ have the same class.
    \end{itemize}
\end{proof}
\end{exercise}

\section{Preprocessing}

Le feature si distinguono in 
\begin{itemize}
	\item feature categoriche (o simboliche)
	\begin{itemize}
		\item nominali (no ordine)
		\item ordinali (ordne, no distanze)
	\end{itemize}
	\item feature quantitative (o numeriche)
	\begin{itemize}
		\item intervalli
		\item ratio
	\end{itemize}
\end{itemize}

\subsection{Codifica OneeHot}

Vettore con tante componenti quante i possibili valori delle variabili.

\subsection{title}

\section{Esami passati}

\subsection{Esame del 13/05/2013}

\begin{exercise}{(1)}
    Spiegare gli ingredienti fondamentali del supervised learning e il
    ruolo della VC-dimension.
    \begin{proof}
        Il supervised learning è una tecnica di apprendimento che
        consente di apprendere delle funzioni target grazie ad un
        algoritmo di apprendimento e ad un insieme di esempi. In
        particolare nel supervised learning le ``forze'' in gioco sono
        \begin{itemize}
            \item la funzione target $\fund{f}{\calX}{Y}$, ovvero la
              funzione che si vuole apprendere,
            \item gli esempi $(\vec{x}_1, y_1), \ldots, (\vec{x}_n,
              y_n)$ che descrivono punti della funzione target,
            \item lo spazio delle ipotesi $\calH$, ovvero lo spazio di
              ricerca entro il quale si cercano funzioni che
              approssimano al meglio $f$,
            \item l'algoritmo di apprendimento che esplora $\calH$ per
              trovare una funzione $g$ tale che $g \approx f$.
        \end{itemize}
    
        Nell'apprendimento supervisionato, al contrario di altri tipi
        di apprendimento, il training set è formato da coppie che
        rappresentano l'input e l'output della funzione. Conoscere
        anche il risultato atteso della funzione su quell'input è di
        particolare rilevanza e ci permette di lavorare con strumenti
        che sfruttano molto questa proprietà (esempio: algoritmo di
        aggiornamento dei pesi della rete neurale).
        
        La VC-dimension è una misura della complessità dello spazio
        delle ipotesi $\calH$. Ci permette di capire quanto lo spazio
        delle ipotesi $\calH$ è ricco o meno, ed in particolare più la
        VC-dimension è alta più lo spazio delle ipotesi è vasto e in
        questo spazio riusciamo a trovare una funzione che ``fitta''
        meglio la funziona target; questo però ne inficia la
        generalità in quanto una funzione $g$ che approssima molto
        bene $f$ solo sugli input del training set è poco utile.
        
        Alcuni esempi di spazio delle ipotesi sono gli iperpiani in
        $\Rset^2$ o $\Rset^n$, dei cerchi, dei rettangoli... e la
        VC-dimension ne misura la complessità. In particolare la
        VC-dimension è la cardinalità massima dell'insieme dei punti
        frazionabili nello spazio per ogni dicotomia.
        
        Più formalmente, dato $S \subset \calX$, dove $\calX$ è lo
        spazio di input
        \[
            \forall S' \subseteq S \itc \exists h \in \calH \st \forall x \in S \itc h(x) = 1 \Leftrightarrow x \in S'
        \] 
        ovvero $S'$ è frammentabile da $h$.
        Quindi
        \[
            VC(\calH) = max \mid S \mid \itc S\text{ è frammentato da }\calH,\text{ su }S \subseteq \calX
        \]
        
        Da ciò si evince che la VC-dimension, sullo spazio delle
        ipotesi degli iperpiani in $\Rset^2$ è 3.
    \end{proof}
\end{exercise}

\begin{exercise}{(2, non fatto)}
	Nel contesto dell'apprendimento dei concetti, definire il Version Space e spiegare come tale concetto è utilizzato nell'apprendimento.
\end{exercise}

\begin{exercise}(3)
    Definizione di errore ideale ed empirico, e discutere in che modo
    possono essere messi in relazione tra loro.
    
    \begin{proof}
        Dato un training set composto da un certo numero di coppie
        $(\vec{x},y)$, queste sono generate secondo una funzione di
        probabilità $P(\vec{x},y) =
        P(\vec{x})P(y\mid\vec{x})$. Prendendo un ipotesi
        ``plausibile'' da $\calH$ come $\fund{g}{\calX}{\calY}$,
        l'errore ideale è l'errore compiuto su un certo input dalla
        funzione $g$ considerando la probabilità $P(\vec{x},y)$,
        mentre l'errore empirico è l'errore commesso da $g$ sul
        training set. Una buona ipotesi dovrebbe minimizzare l'errore
        ideale.
    \end{proof}
\end{exercise}

\begin{exercise}{(4)}
    Spiegare le strategie di scelta dell’attributo ottimo negli alberi
    di decisione.
    
    \begin{proof}
        La costruzione dell'albero è la fase più importante per gli
        alberi di decisione. Una buona costruzione dell'albero può
        sicuramente migliorare le performance e la reazione
        dell'albero ad input sconosciuti, e l'algoritmo ID3
        rappresenta uno dei modi per creare gli alberi dai dati a
        dispoziione.
        
        L'algoritmo ID3 prende in input $S$ l'insieme degli esempi e
        $A$ l'insieme degli attributi, e si compone delle seguenti
        fasi:
        \begin{itemize}
            \item crea la radice T
            \item se l'insieme $S$ ha elementi tutti della stessa
              classe restituisci T con etichetta S
            \item se l'insieme $A$ è vuoto restituisci T con etichetta
              ricorrente maggiore in $S$
            \item scegli l'attributo ottimo
            \item partiziona $S$ in base ai possibili valori che
              possono assumere per l'attributo scelto e restituisci T
              con sottoalberi $ID3(S_{a=v_j}, A-a), \forall j$.
        \end{itemize}
    
        La scelta dell'attributo ottimo è effettuata secondo diversi
        criteri, ID3 si basa sul concetto di entropia e information
        gain. L'entropia è una misura del disordine, che applicata
        all'insieme $S$ ci permette di dire se il numero di elementi
        contenuti in $S$ è più o meno classificato
        correttamente. Un'altra entropia (vicina ad 1) indica che $S$
        contiene circa lo stesso numero di elementi per ogni
        classe. L'attributo che genera questa entropia è quindi un
        buon candidato per essere scelto e per pratizionare $S$. ID3
        si basa anche sull'information gain, che, tramite l'entropia,
        ci permette di capire quale attributo scegliere in base al
        guadagno di informazione.
        
        In particolare, l'entropia è calcolata (su $n$ classi) come
        \[
        \sum_{c=1}^{n} p_c log(p_c)
        \]
        dove $p_c = \frac{\mid S_c\mid}{\mid S \mid}$.
        Il guadagno di informazione invece 
        \[
        G(S, a) = E(S) - X
        \]
        con $X$ la media pesata sugli elementi di una certa classe
        dell'entropia di quella classe, ovvero
        \[
            G(S,a) = E(S) - \sum_{v \in V}\frac{|S_{a=v}|}{|S|} E(S_{a=v})
        \]
        
        Altri criteri per definire l'information gain sono
        \begin{itemize}
            \item cross entropy,
            \item gini index
            \item miscalssification.
        \end{itemize}
        Che hanno delle curve più ripide rispetto all'entropia. Per
        esempio la curva della miscalssification è un ``triangolo''.
    \end{proof}
\end{exercise}

\subsection{Esame del 10/06/2013}

\begin{exercise}{(1)}
    Presentare i criteri di valutazione che si possono utilizzare per
    misurare la bontà di un classficatore. Discuterne l'utilizzo.
    
    \begin{proof}
    	...
    \end{proof}
\end{exercise}

\begin{exercise}{(2)}
    Presentare e discutere i criteri esterni e interni presentati a
    lezione per valutare un sistema di clustering.
\end{exercise}

\begin{exercise}{(3)}
    Presentare i concetti matematici fondamentali per la definizione
    di una Support Vector Machine nel caso di dati non linearmente
    separabili. Discuterne pregi e difetti.
    
    \begin{proof}
    	Una SVM è uno strumento matematico che ci consente di separare linearmente dei dati. Nello spazio delle ipotesi degli iperpiani ci consente di trovare un iperpiano che, appunto, separa i dati.
    	
    	In particolare con una SVM è possibile porre il problema di modo che quello che venga risolto sia un problema di ottimizzazione con vincoli, tramite il quale riusciamo a trovare una soluzione ottima. Per fare questo, nello spazio delle ipotesi degli iperpiani, si introduce il concetto di distanza geometrica, ovvero dato un iperpiano $\vec{w} \cdot \vec{x} + b = 0$, la distanza di $\vec{x}$ dall'iperpiano è la misura algebrica 
    	\[
    		g(\vec{x}) = \vec{w} \cdot \vec{x} + b.
    	\]
    	Possiamo scrivere 
    	\[
    		\vec{x} = \vec{x_p} + r \frac{w}{|| w ||}
    	\]
    	dove $x_p$ è la proiezione del punto $\vec{x}$ sull'iperpiano, ed $r$ è la distanza algebrica desiderata dall'iperpiano.
    	
    	Il margine è quindi dato da 
    	\[
    		g(\vec{x}) = \vec{w} \cdot \vec{x} + b \quad\text{and}\quad \vec{x} = \vec{x_p} + r \frac{w}{|| w ||}
    	\]
    	da cui è facile vedere che per minimizzare l'errore bisogna massimizzare il margine tra i punti di classi differenti. Più è alto il margine tra le classi più sarà piccolo l'errore di classificazione.
    	
    	Possiamo osservare anche che la VC-dimension ottima per gli iperpiani 
    	\[
    		VC_{opt} \leq \min \{ \lceil \frac{R^2}{\rho^2} \rceil, m \} + 1
   		\]
   		dove $R$ è il diametro della più piccola palla che racchiude tutti i punti di input ed $m$ è dato da $\Rset^m$ (NB: iperpiani in $\Rset^m$ hanno $VC=m+1$).
   		
   		A questo punto il problema si è ridotto nel trovare il più piccolo $\vec{w}$ tale che i punti dell'input distino dall'iperpiano almeno 1, ovvero
   		\[
   			min_{\vec{w},b} \frac{1}{2} ||w||^2
   		\]
   		con vincoli
   		\[
   			\forall i \in 1..n, y_i(\vec{w} \cdot \vec{x_i} + b) \geq 1
   		\]
   		
   		Se gli esempi non sono linearmente separabili esistono diversi modi di aggirare il problema.
   		\begin{itemize}
   			\item Aggiungere variabili \emph{slack} che aggiungono una certa tolleranza al vincolo di essere $\geq 1$. Inoltre è possibile penalizzere le slack variabile sommandole all'oggetto da minimizzare, ovvero
   			\[
   				min_{\vec{w},b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i
   			\]
   			$C$ può essere usato per controllare l'overfitting: maggiore è il $C$, meno il comportamento reale dei dati conta, ovvero $||\vec{w}||$ ha meno rilevanza e i dati vengono fittati meglio; minore è il $C$ e più le slack non contano nella sommatoria, quindi si cerca di massimizzare il margine a discapito dell'errore nel training set.
   			
   			\item Possiamo mappare i dati di input in uno spazio delle feature (di dimensionalità maggiore) dove possibilmente i dati diventano linearmente separabili.
   			E con il kernel trick non abbiamo bisogno di rappresentare effettivamente i vettori nello spazio delle feature.
   			(aggiungere altro??)
   		\end{itemize}
    \end{proof}
\end{exercise}

\begin{exercise}{(4)}
    Discutere come la teoria delle probabilità, e in particolare
    l'approccio bayesiano, possa essere utilizzata nell'ambito
    dell'Apprendimento Automatico.
\end{exercise}

% *********************
\chapter{Advanced Topics on Programming Languages}

\section{Mini functional language}

\subsection{Esercizio 1.1}

\begin{exercise}
    Solve the follogin exercises on high-order functions. \todo{Translate}
    \begin{itemize}
        \item write a term that represent an high-order function
          (i.e., takes another function as input). Scrivere inoltre un
          programma che usa una funzione higher.
        \item Scrivere una funzione che restituisce una funzione.
    \end{itemize}

\begin{proof}
    Parte 1:
    \begin{verbatim}
    -- high order
    fn x.x

    -- apply func arg
    --   Apply the function `func` to argument `arg`.
    fn x. (fn y. (x y) 1) fn z. z+1
    \end{verbatim}

    Parte 2:
    \begin{verbatim}
    fn x.x fn y.y+1
    \end{verbatim}

\end{proof}

\end{exercise}

\subsection{Esercizio 1.4}

\begin{exercise}
    Definire formalmente la nozione di sottotermini di un termine M
    del nostro linguaggio.
    \begin{proof}
        ??? \fixme{Finish this exercise}
    \end{proof}
\end{exercise}

\subsection{Esercizio Extra 1}

\begin{exercise}
    Definire la semantica dell'applicazione con \emph{call-by-name}.
    \begin{proof}
        \begin{equation}
        \rulename{BETA.N}
        \prooftree
        \justifies
        fn \ x .\ M\ N \to M \{ x := N \}
        \endprooftree
        \end{equation}

        \begin{equation}
        \rulename{APP.N}
        \prooftree
        M \to M'
        \justifies
        M \ N \to M' \ N
        \endprooftree
        \end{equation}
         \fixme{Needs review}
    \end{proof}
\end{exercise}

\subsection{Esercizio Extra 2}

\begin{exercise}
    Dimostrare formalmente che la valutazione (esecuzione) di un
    programma è deterministica. Se $M \to M'$ e $M \to M''$ allora $M'
    = M''$.

    \begin{proof}
        Si enuncia prima, in modo formale, la proposizione.
        \[
        \forall M, M', M'' \in Term: M \to M' \land M \to M'' \Rightarrow M' = M''
        \]
        Ciò viene mostrato per induzione sulla struttura di M.

        \begin{itemize}
            \item Caso base. Prendiamo in esame il caso $M = true$.

            Applicando l'enunciato abbiamo
            \[
            true \not\to M' \land true \not\to M'' \Rightarrow M' = M''
            \]
            ma questo è banalmente vero, visto che $false \Rightarrow
            true$ è $true$.

            Gli altri casi sono analoghi.

            \item Passo induttivo. Prendiamo in esame $M = N_1 + N_2$.

            Applicando l'enunciato ottenuamo
            \[
            N_1 + N_2 \to N' \land N_1 + N_2 \to N'' \Rightarrow N' = N''
            \]

            Per ipotesi induttiva sappiamo che vale
            \begin{equation*}
            \begin{split}
            N_1 \to N_1' \land N_1 \to N_1'' & \Rightarrow N_1' = N_1'' \\
            N_2 \to N_2' \land N_2 \to N_2'' & \Rightarrow N_2' = N_2''
            \end{split}
            \end{equation*}
            e quindi
            \[
            N' = N'' \Leftrightarrow N_1' + N_2' = N_1'' + N_2''
            \]

            A questo punto, sapendo che anche la somma è un'operazione
            deterministica concludo che $M' = M''$.
        \end{itemize}
    \end{proof}
\end{exercise}

\subsection{Exercise 3.2}

\begin{exercise}
    Find a context $\Gamma$ such that $\Gamma \vdash x\ y : \Bool$ is derivable.

    \begin{proof}
        The syntax is ambiguous. We can disambiguate in two ways: $f\ (x\ y)$ or $(f\ x)\ y$.

        Case $f\ (x\ y)$.
        \begin{align*}
            \prooftree
              \prooftree
                \nohyp
                \justifies
                  \Gamma \vdash f : \tT \to \Bool
                \using
                  f : \tT_1 \to \Bool \in \Gamma
              \endprooftree
              \qquad
              \prooftree
                \prooftree
                  \nohyp
                  \justifies
                    \Gamma \vdash x : \tT_2 \to \tT_1
                  \using
                    x:\tT_1 \to \tT_1 \in \Gamma
                \endprooftree
                \qquad
                \prooftree
                  \nohyp
                  \justifies
                    \Gamma \vdash y : \tT_2
                  \using
                    y:\tT_2 \in \Gamma
                \endprooftree
                \justifies
                  \Gamma \vdash (x\ y) : \tT_1
              \endprooftree
              \justifies
                \Gamma \vdash f\ (x\ y) : \Bool
            \endprooftree
        \end{align*}
    \end{proof}
\end{exercise}

\subsection{Exercise 3.3}

\begin{exercise}
    Is $\Gamma \vdash x\ x : \tT$ derivable? If yes find a derivation
    for some $\Gamma, \tT$, otherwise prove that is not derivable.

    \begin{proof}
        We can construct the proof tree.
        \begin{align*}
            \prooftree
              \prooftree
                \nohyp
                \justifies
                  \Gamma \vdash x : \tT_1 \to T
                \using
                  x : \tT_1 \to T \in \Gamma
              \endprooftree
              \prooftree
                \nohyp
                \justifies
                  \Gamma \vdash x : \tT_1
                \using
                  x : \tT_1 \in \Gamma
              \endprooftree
              \justifies
                \Gamma \vdash x\ x : \tT
            \endprooftree
        \end{align*}
        We obtain a $\Gamma$ in which $x$ should be two different
        things for each $T$, thus, the judgment is not derivable.
    \end{proof}
\end{exercise}

\subsection{Exercise 3.8}

\begin{lemma}
    \label{atpl_ex_3_8_lemma}
    Given a context $\Gamma$, if a term has a type in $\Gamma$ then
    it's type is unique and it's derivation is unique.
\end{lemma}

\begin{exercise}
    Formalize and prove the Lemma \ref{atpl_ex_3_8_lemma}.

    \begin{proof}
        First of all we need to write down mathematically the lemma.

        \begin{equation*}
        \begin{split}
        \forall \Gamma &\itc \forall T_1, T_2 \itc \Gamma \vdash M : \tT \Rightarrow \\
        &\Gamma \vdash M:T_1 \land \Gamma \vdash M:T_2 \Rightarrow T_1 = T_2 \\
        & ???
        \end{split}
        \end{equation*}
    \end{proof}
\end{exercise}

\subsection{Exercise 3.14}

\begin{exercise}
    Prove that if $\Gamma \vdash M: \tT$ is derivable then $\FV(M) \subseteq \dom(\Gamma)$.

    \begin{proof}
        By structural induction on $M$.

        \begin{itemize}
            \item Case $M = \true$. $M$ is derivable using
              $\mathrm{T-TRUE}$ rule. Then we know that $\FV(M) =
              \FV(true) = \emptyset$ by definition and $\emptyset
              \subseteq \dom(\Gamma)$, thus $\FV(M) \subseteq
              \dom(\Gamma)$.
            \item Case $M = \false$ and $M=n$ are identical to case $M
              = \true$.
            \item Case $M = x$. $M$ is derivable using
              $\mathrm{T-VAR}$ and the rule is applicable only if $x
              \in \Gamma$. Then we know $\FV(M) = \FV(x) =
              \{x\}$. Thus, $\FV(M) = \FV(x) \subseteq \dom(\Gamma)$.
            \item Case $M = M_1 + M_2$. $M$ is derivable by
              $\mathrm{T-SUM}$.
            \[
                \rulename{T-SUM}
                \prooftree
                  \Gamma \vdash M_1:\mathrm{Nat} \qquad \Gamma \vdash M_2:\mathrm{Nat}
                  \justifies
                  \Gamma \vdash M_1+M_2 :\mathrm{Nat}
                \endprooftree
            \]
            Then we know that
            \[
                \FV(M) = \FV(M_1 + M_2) = \FV(M_1) \cup \FV(M_2)
            \]
            and by the inductive hypothesis
            \[
                \FV(M_1) \in \Gamma \land \FV(M_2) \in \Gamma
            \]
            so
            \[
                \FV(M_1) \cup \FV(M_2) \in \Gamma
            \]
            \item Case $M = \condif{M_1}{M_2}{M_3}$ and $M = M_1
              M_2$. Can be proved as done in $M = M_1 + M_2$ case.
            \item Case $M = fx:\tT_1.M:\tT_1 \to \tT_2$. $M$ is
              derivable using $\mathrm{T-FUN}$
            \[
                \rulename{T-FUNC}
                \prooftree
                    \Gamma,x:\tT_1 \vdash M:\tT_2
                \justifies
                    \Gamma \vdash f x:\tT_1 . M:\tT_1 \to \tT_2
                \endprooftree
            \]
            We know that $\FV(M) = \FV(fx:\tT_1.M:\tT_1 \to \tT_2) =
            \FV(M) \setminus \{x\}$. Let $\Gamma' = \Gamma, x$. By the
            inductive hypothesis we know that $\FV(M) \subseteq \Gamma
            = \Gamma' \setminus \{x\}$, thus $\FV(M) \subseteq
            \dom(\Gamma')$.

        \end{itemize}
    \end{proof}
\end{exercise}

\section{Types uniqueness}
 \fixme{Translate into english.}

\begin{exercise}
    Formalize and prove the Theorem \ref{th_type_uniqueness}

    \begin{proof}
        First of all we must formalize the theorem in order to prove it.
        \begin{align*}
            \forall \Gamma, \tT \itc \Gamma \vdash M : \tT \Rightarrow \\
            (\Gamma \vdash M : T_1 \land \Gamma \vdash M : T_2 \Rightarrow T_1 = T_2) \\
            \land (??)
        \end{align*}
        From this definition we can prove the theorem using two
        sub-lemmas: Lemma \ref{atpl_ex_type_uniqueness_lemma1} and
        \ref{atpl_ex_type_uniqueness_lemma2}.
    \end{proof}
\end{exercise}

\begin{theorem}
    \label{th_type_uniqueness}
    Given a context $\Gamma$, if a term has a type in $\Gamma$ then
    it's type is unique and it's derivation is unique.
\end{theorem}

\begin{lemma}
    \label{atpl_ex_type_uniqueness_lemma1}
    \begin{align*}
        \forall \Gamma, \tT \itc \Gamma \vdash M : \tT \Rightarrow \\
        \Gamma \vdash M : T_1 \land \Gamma \vdash M : T_2 \Rightarrow T_1 = T_2
    \end{align*}

    \begin{proof}
        By structural induction on $M$.

        Case $M = \true$. We obtain
        \[
            \Gamma \vdash \true : \tT_1 \land \Gamma \vdash \true : \tT_2
        \]
        and by the $\mathrm{T-TRUE}$ rule we know that $M$ is
        derivable in $\Gamma$. By the inversion lemma, instead, we
        know that $\tT_1 = \Bool$ and $\tT_2 = \Bool$, so the lemma
        holds.

        Case $M = \false$. Identical to the one above.

        Case $M = n$. Identical to the two above, using the
        $\mathrm{T-NAT}$ rule.

        Case $M = M_1 + M_2$. In this case we obtain
        \[
            \Gamma \vdash M_1 + M_2 : \tT_1 \land \Gamma \vdash M_1 + M_2 : \tT_2
        \]
        and we know that is derivable using the rule $\mathrm{T-SUM}$, so we have
        \[
            \prooftree
                \Gamma \vdash M_1 : \tT_1
                \qquad
                \Gamma \vdash M_2 : \tT_1
              \justifies
                \Gamma \vdash M_1 + M_2 : \tT_1
            \endprooftree
        \]
        and
        \[
            \prooftree
                \Gamma \vdash M_1 : \tT_2
                \qquad
                \Gamma \vdash M_2 : \tT_2
              \justifies
                \Gamma \vdash M_1 + M_2 : \tT_2
            \endprooftree
        \]
        Then, by the inversion lemma we note that the type of $M_1 +
        M_2$, $M_1$, $M_2$ is $\Nat$. Now we know that the types on
        the last level of the tree match and we can apply the
        inductive hypothesis, that holds on the sub-expression, so the
        lemma holds.  \fixme {Riscrivere questa frase in modo più
          formale (meno scritte, più formule).}

        Case $M = \condif{M_1}{M_2}{M_3}$, $M = \fnfun{x}{M_1}$, $\fnapp{M_1}{M_2}$ are left as exercises to the reader.
    \end{proof}
\end{lemma}

% *********************
\chapter{Computability}

\section{Course Notes}

\subsection{Algorithm} 

An algorithm is a procedure made by a set of simple steps that allows
to obtain a result (i.e., transform some input in some other output).

\subsection{Mathematical Notation}

\begin{itemize}
    \item \textbf{Cartesian} Given $A, B$ sets, $A \times B = \{ (a,b)
      \mid a \in A, b \in B\}$.
    \item \textbf{Relation} Given $A, B$ sets, $r \subseteq A \times
      B$ is a relation.
    \item \textbf{Function} $\fund{f}{A}{B}$ is a particular type of
      relation that maps every element of $A$ with one and only one
      element of $B$.
    \item \textbf{Domain} $\dom(f) = \{ a \in A \mid \exists b \in B
      \st f(a) = b \}$.
    \item \textbf{Size} $|A| = |B|$ if exists $\fund{f}{A}{B}$
      biunivoca\fixme{Translate}.
\end{itemize}

\subsection{Calculation Model}

\begin{itemize}
    \item $\calA$, the algorithms class.
    \item $\calF$, the set of unary functions
      $\fund{f}{\Nset}{\Nset}$.
    \item $\forall A \in \calA \itc \fund{f_A}{\Nset}{\Nset}$ the
      calculated function.
    \item Set of calculated functions by $A$
    \begin{align*}
        \calF_A &= \{ f \in \calF \mid \exists A \in \calA \st f = f_A \} \\ 
          &= \{ f_A \mid A \in \calA \} \\
          &\subseteq \calF
    \end{align*}.
\end{itemize}

\begin{lemma}{(Calculable functions are countable)}
    \begin{proof}
        Let $I$ the set of instructions (finite by definition). $\calA
        = I \cup I \times I \cup I \times I \times \ldots$. So $\calA$
        is an union of enumerable sets.
        \[
          |\calA| = | \bigcup_{i \geq 1} I^i | \leq | \Nset |
        \]
    \end{proof}
    \fixme{then??}
\end{lemma}

\begin{lemma}{(All functions are not countable)}
    \todo{Add this}
\end{lemma}

\subsection{The  $\calR$ class}

The $\calR$ class is the minimal class of functions that contains base
functions
\begin{itemize}
    \item successor,
    \item zero,
    \item project
\end{itemize}
and closed by 
\begin{itemize}
    \item generalized composition,
    \item primitive recursion,
    \item unlimited minimalization.
\end{itemize}

\section{Exercises from Notes}

\begin{exercise}{(Exercise 1.1)}
    Let $URM^-$ be the $URM$ machine without the $S(n)$ instruction,
    replaced by $P(n)$ that calculates $r_n \leftarrow r_n - 1$. What
    is the relation between $\calC$ and $\calC^-$?
    
    \begin{proof}
        We need to prove that $\calC \subseteq \calC^-$ and $\calC^-
        \subseteq \calC$.
        
        Let's start from $\calC^- \subseteq \calC$. This is true
        because we can build an $URM$ program that calculates $n-1$.
        
        The case $\calC \subseteq \calC^-$ it's not true. By the Lemma
        \ref{comp_ex_1_1_lemma} we know that the content of a $URM^-$
        machine register cannot be greater than $\max \{ \vec{x} \}$
        and this does not allow us to calculate $S(n).$
    \end{proof}
\end{exercise}

\begin{lemma}
    \label{comp_ex_1_1_lemma}
    The content of $URM^-$ registers is always $\leq \max \vec{x}$.
    
    \begin{proof}
        By induction on the length of program $h$.
        
        \noindent Case $h = 0$. Trivially true because the content of
        the memory is \[ x_1\ x_2\ \ldots\ x_l\ 0\ 0\ \ldots \]
        
        \noindent Case $h + 1$. The $i$-th instruction of a program
        can be either
        \begin{itemize}
            \item $T(m,n)$, that is $r_n \leftarrow t_m$ and we have
              two cases
            \begin{itemize}
                \item $m \leq \rho(P) \Rightarrow r_n \leq \max
                  \{\vec{x}\}$.
                \item $m > \rho(P) \Rightarrow r_n = 0$.
            \end{itemize}
            \item $P(n)$, then $r_n \leftarrow r_n - 1$ and this
              implies $r_n \leq \max \{\vec{x}\}$.
            \item $Z(n)$, then $r_n \leftarrow 0$ and this implies
              $r_n \leq \max \{\vec{x}\}$.
            \item $J(m,n,t)$, that does not modify the memory so we
              $r_n$ is left unchanged.
        \end{itemize}
        So $\forall i \in N \itc r_i \leq \max \{ \vec{x} \}$.
    \end{proof}
\end{lemma}



\section{Exercises}

\subsection{URM Machine}

\begin{exercise}
    Find a $URM$-program that calculates $x \div 2$.

    \begin{proof}
        Memory initialization: $r_1 = x, r_2 = 2, r_3 = 0, r_4 = 0$.

\begin{verbatim}
LOOP: J(1,4,RIS)
      S(3)
      S(4)
      S(4)
      J(1,1,LOOP)
 RIS: T(3,1)
 END:
\end{verbatim}
    \end{proof}
\end{exercise}

\begin{exercise}
    Find a $URM$-program that calculates $\lceil x \div 2 \rceil$.

    \begin{proof}
        Memory initialization: $r_1 = x, r_2 = 2, r_3 = 0, r_4 = 0, r_5 = 0$.

\begin{verbatim}
LOOP1: J(1,5,RIS)
       S(4)
       Z(3)
LOOP2: J(2,3;LOOP1)
       S(5)
       S(3)
       J(1,1,LOOP2)
 RIS:
 END:
\end{verbatim}
    \end{proof}
\end{exercise}

\begin{exercise}
    Let $URM^-$ be a $URM$-machine without the jump instruction.
    Prove that $\calC^- \not\subseteq \calC$. (Note: for simplicity
    consider only unary functions, $f: \Nset \to \Nset$)

    \begin{proof}
        Intuitively, a $URM^-$ program must stop in a finite number of
        steps $l(P)$ (i.e., the length of the program).  For this
        reason we can compute only functions like
        \[ f(x) = c \]
        or
        \[ f(x) = x + c \]

        We need to prove that the output for an $URM^-$ program (i.e.,
        the content of the first register) is in the desidered form.
        However, we need to prove that all registers are in the
        desidered form.\footnote{If we prove the proposition proving
          the condition only for the first register, when treating the
          transfer instruction we cannot say anything on the content
          of other registers, for this we cannot end the proof.}

        So, we want to prove
        \[ r_i(x, j) = c \]
        or
        \[ r_i(x, j) = x + c \]
        where $x$ is the input, $j$ is the number of steps (executed
        instructions) and $i$ is the index of a register.

        We can prove that by induction on $j$.
        \begin{itemize}
            \item Base case. $j = 0$.
            \begin{itemize}
                \item $r_1(x, 0) = x$ or $r_1(x, 0) = 0$,
                \item $r_{i > 1} (x, 0) = 0$.
            \end{itemize}

            \item Inductive case. $j \to j + 1$.

            We have three cases based on the type of the $j+1$-th
            instruction
            \begin{itemize}
                \item $Z(n)$. $r_n(x, j+1) = 0$, that is what we want.
                \item $S(n)$. $r_n(x, j+1) = r_n(x, j) + 1$, that by
                  inductive hypothesis and by sum on naturals holds.
                \item $T(m, n)$. $r_n(x, j + 1) = r_m(x, j)$, that by
                  inductive hypothesis holds.
            \end{itemize}
        \end{itemize}

        We have proved that all registers of a $URM^-$ machine, for
        each program $P$, keeps the form $c$ or $x + c$. From this we
        can conclude that $\calC^- \not\subseteq \calC$.
    \end{proof}

\end{exercise}

\begin{exercise}
    Write the definition of URM-computability.
\end{exercise}

\end{document}
